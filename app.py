"""
æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢ã‚¢ãƒ—ãƒª v9
- Nominatim/åº§æ¨™å¤‰æ› å®Œå…¨å‰Šé™¤
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé§…åãƒ»å¸‚åŒºç”ºæ‘ï¼‰ã§ä½æ‰€æ–‡å­—åˆ—ã‚’æ¤œç´¢
- å„åº—èˆ—ã«Googleãƒãƒƒãƒ—ãƒªãƒ³ã‚¯ï¼ˆä½æ‰€æ¸¡ã—ã€APIã‚­ãƒ¼ä¸è¦ï¼‰
- çµã‚Šè¾¼ã¿çµæœã‚’ã¾ã¨ã‚ã¦Googleãƒãƒƒãƒ—æ¤œç´¢ã™ã‚‹ãƒœã‚¿ãƒ³
- CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogleãƒã‚¤ãƒãƒƒãƒ—ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ï¼‰
"""
import streamlit as st
import pandas as pd
import urllib.parse
from pathlib import Path
from pdf_parser import extract_stores_from_pdf

st.set_page_config(
    page_title="æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢",
    page_icon="ğŸ«",
    layout="wide",
)

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap');
html, body, [class*="css"] { font-family: 'Noto Sans JP', sans-serif; }
.store-card {
    background: #fff;
    border: 1px solid #e0e0e0;
    border-left: 5px solid #1a73e8;
    border-radius: 6px;
    padding: 12px 16px;
    margin: 6px 0;
}
.store-brand { font-size: 0.8em; color: #666; }
.store-name  { font-size: 1.05em; font-weight: 700; color: #202124; }
.store-addr  { font-size: 0.85em; color: #444; margin-top: 2px; }
.store-tel   { font-size: 0.82em; color: #888; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ« æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢")
st.caption("PDFã‚’èª­ã¿è¾¼ã‚“ã§ã€é§…åãƒ»ã‚¨ãƒªã‚¢ã§å„ªå¾…åº—èˆ—ã‚’çµã‚Šè¾¼ã‚ã¾ã™ï¼ˆå®Œå…¨ç„¡æ–™ãƒ»APIã‚­ãƒ¼ä¸è¦ï¼‰")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ã‚µã‚¤ãƒ‰ãƒãƒ¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
with st.sidebar:
    st.header("ğŸ“‚ PDFã‚’èª­ã¿è¾¼ã‚€")
    uploaded = st.file_uploader(
        "æ ªä¸»å„ªå¾…PDF",
        type=["pdf"],
        accept_multiple_files=True,
    )

    # pdfs/ ãƒ•ã‚©ãƒ«ãƒ€ã‚‚è‡ªå‹•èª­ã¿è¾¼ã¿
    pdf_dir = Path("pdfs")
    preloaded = sorted(pdf_dir.glob("*.pdf")) if pdf_dir.exists() else []
    if preloaded:
        st.caption(f"ğŸ“ pdfs/ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ {len(preloaded)} ä»¶è‡ªå‹•èª­ã¿è¾¼ã¿")

    st.divider()
    st.header("ğŸ” ã‚¨ãƒªã‚¢çµã‚Šè¾¼ã¿")
    keyword = st.text_input(
        "é§…åãƒ»å¸‚åŒºç”ºæ‘ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰",
        placeholder="ä¾‹ï¼šæ¨ªæµœã€æ–°å®¿ã€å·å´å¸‚ã€æ¸‹è°·",
        help="ä½æ‰€ãƒ»åº—èˆ—åã‚’éƒ¨åˆ†ä¸€è‡´ã§æ¤œç´¢ã—ã¾ã™"
    )

    st.divider()
    st.header("ğŸ—‚ï¸ éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    selected_prefs = []  # å¾Œã§å‹•çš„ç”Ÿæˆ

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# PDF è§£æ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
all_stores = []

sources = list(uploaded or [])

# preloaded ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ File-like ã«å¤‰æ›
class _FileProxy:
    def __init__(self, p: Path):
        self.name = p.name
        self._data = p.read_bytes()
        self._pos = 0
    def read(self, n=-1):
        d = self._data[self._pos:]
        self._pos = len(self._data)
        return d
    def seek(self, p): self._pos = p

for p in preloaded:
    sources.append(_FileProxy(p))

if not sources:
    st.info("ğŸ‘† ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    st.stop()

for src in sources:
    try:
        stores = extract_stores_from_pdf(src, source_type="upload")
        all_stores.extend(stores)
    except Exception as e:
        st.error(f"âŒ {src.name}: {e}")

if not all_stores:
    st.error("åº—èˆ—æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    st.stop()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼å‹•çš„ç”Ÿæˆï¼‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
all_prefs = sorted(set(s.get("pref", "") for s in all_stores if s.get("pref")))

with st.sidebar:
    selected_prefs = st.multiselect(
        "éƒ½é“åºœçœŒ",
        options=all_prefs,
        default=all_prefs,
        help="è¡¨ç¤ºã™ã‚‹éƒ½é“åºœçœŒã‚’é¸æŠ"
    )

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# çµã‚Šè¾¼ã¿
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
filtered = all_stores

# éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
if selected_prefs:
    filtered = [s for s in filtered if s.get("pref") in selected_prefs]

# ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆä½æ‰€ãƒ»åº—èˆ—åã‚’éƒ¨åˆ†ä¸€è‡´ï¼‰
if keyword.strip():
    kw = keyword.strip()
    filtered = [
        s for s in filtered
        if kw in s.get("address", "") or kw in s.get("name", "")
    ]

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# çµæœãƒ˜ãƒƒãƒ€ãƒ¼
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
col_stat, col_btn = st.columns([3, 2])
with col_stat:
    total_msg = f"å…¨ **{len(all_stores)}** ä»¶ä¸­ **{len(filtered)}** ä»¶ã‚’è¡¨ç¤º"
    if keyword.strip():
        total_msg += f"ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ã€Œ{keyword}ã€ï¼‰"
    st.markdown(total_msg)

with col_btn:
    if filtered:
        # ã¾ã¨ã‚ã¦Googleãƒãƒƒãƒ—ã§æ¤œç´¢ï¼ˆæœ€åˆã®1ä»¶ã®ä½æ‰€ã§æ¤œç´¢ã—ã€å‘¨è¾ºã‚’ç¢ºèªï¼‰
        if keyword.strip():
            gmaps_area_url = (
                "https://www.google.com/maps/search/"
                + urllib.parse.quote(keyword.strip() + " å‘¨è¾º")
            )
        else:
            gmaps_area_url = "https://www.google.com/maps"
        st.link_button(
            f"ğŸ—ºï¸ ã€Œ{keyword or 'ã‚¨ãƒªã‚¢'}ã€ã‚’Googleãƒãƒƒãƒ—ã§é–‹ã",
            gmaps_area_url,
            use_container_width=True,
        )

if not filtered:
    st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹åº—èˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    st.stop()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogleãƒã‚¤ãƒãƒƒãƒ—ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨ï¼‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
df = pd.DataFrame([{
    "åº—èˆ—å":     s.get("name", ""),
    "ä½æ‰€":       s.get("address", ""),
    "é›»è©±ç•ªå·":   s.get("tel", ""),
    "éƒ½é“åºœçœŒ":   s.get("pref", ""),
    "GoogleMap":  "https://www.google.com/maps/search/?api=1&query="
                  + urllib.parse.quote(s.get("address", "")),
} for s in filtered])

col_dl1, col_dl2 = st.columns(2)
with col_dl1:
    csv_bytes = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "â¬‡ï¸ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogleãƒã‚¤ãƒãƒƒãƒ—ç”¨ï¼‰",
        data=csv_bytes,
        file_name=f"å„ªå¾…åº—èˆ—_{keyword or 'å…¨ä»¶'}.csv",
        mime="text/csv",
        use_container_width=True,
        help="Googleãƒã‚¤ãƒãƒƒãƒ— â†’ ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â†’ ã“ã®CSVã‚’é¸ã¶ã¨åœ°å›³ã«ãƒ”ãƒ³ãŒç«‹ã¡ã¾ã™",
    )
with col_dl2:
    st.caption("ğŸ’¡ Googleãƒã‚¤ãƒãƒƒãƒ—ã«ã“ã® CSV ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ã¨å…¨åº—èˆ—ãŒåœ°å›³ä¸Šã«ãƒ”ãƒ³è¡¨ç¤ºã•ã‚Œã¾ã™")

st.divider()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# åº—èˆ—ãƒªã‚¹ãƒˆè¡¨ç¤º
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# éƒ½é“åºœçœŒã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—è¡¨ç¤º
from itertools import groupby

pref_order = {p: i for i, p in enumerate(all_prefs)}
filtered_sorted = sorted(filtered, key=lambda s: (
    pref_order.get(s.get("pref", ""), 999),
    s.get("address", "")
))

current_pref = None
for s in filtered_sorted:
    pref = s.get("pref", "")
    if pref != current_pref:
        current_pref = pref
        st.subheader(f"ğŸ“ {pref}")

    name    = s.get("name", "")
    address = s.get("address", "")
    tel     = s.get("tel", "")
    gmaps_url = (
        "https://www.google.com/maps/search/?api=1&query="
        + urllib.parse.quote(address)
    )

    with st.container():
        c1, c2 = st.columns([5, 1])
        with c1:
            st.markdown(
                f"""<div class="store-card">
                  <div class="store-name">{name}</div>
                  <div class="store-addr">ğŸ“® {address}</div>
                  <div class="store-tel">ğŸ“ {tel}</div>
                </div>""",
                unsafe_allow_html=True,
            )
        with c2:
            st.link_button("ğŸ—ºï¸ åœ°å›³", gmaps_url, use_container_width=True)
