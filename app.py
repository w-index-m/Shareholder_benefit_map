"""
æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢ v11
- é§…åå…¥åŠ› â†’ å†…è”µåº§æ¨™DB + ã‚¨ãƒªã‚¢åº§æ¨™DBã§åŠå¾„N kmä»¥å†…ã®å¸‚åŒºç”ºæ‘ã‚’ç‰¹å®š
- è©²å½“ã‚¨ãƒªã‚¢ã®ä½æ‰€ã‚’æŒã¤åº—èˆ—ã‚’çµã‚Šè¾¼ã¿è¡¨ç¤º
- å„åº—èˆ—ã«Googleãƒãƒƒãƒ—ãƒªãƒ³ã‚¯
- çµã‚Šè¾¼ã¿çµæœã‚’ã¾ã¨ã‚ã¦Googleãƒãƒƒãƒ—ã§é–‹ããƒœã‚¿ãƒ³
"""
import streamlit as st
import pandas as pd
import urllib.parse
import math
from pathlib import Path
from pdf_parser import extract_stores_from_pdf
from area_coords import AREA_COORDS, get_station_coord, get_nearby_areas

st.set_page_config(page_title="æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢", page_icon="ğŸ«", layout="wide")

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap');
* { font-family: 'Noto Sans JP', sans-serif; }
.store-card {
    background: #fff;
    border: 1px solid #e0e0e0;
    border-left: 5px solid #1a73e8;
    border-radius: 6px;
    padding: 10px 14px;
    margin: 4px 0;
}
.store-name { font-size: 1em; font-weight: 700; color: #202124; }
.store-addr { font-size: 0.85em; color: #444; margin-top: 2px; }
.store-tel  { font-size: 0.82em; color: #888; }
.area-hint  { font-size: 0.78em; color: #1a73e8; margin-top: 2px; }
</style>
""", unsafe_allow_html=True)

st.title("ğŸ« æ ªä¸»å„ªå¾… åº—èˆ—æ¤œç´¢")

# â”€â”€ ã‚µã‚¤ãƒ‰ãƒãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ“‚ PDFèª­ã¿è¾¼ã¿")
    uploaded = st.file_uploader("æ ªä¸»å„ªå¾…PDF", type=["pdf"], accept_multiple_files=True)
    pdf_dir = Path("pdfs")
    preloaded = sorted(pdf_dir.glob("*.pdf")) if pdf_dir.exists() else []
    if preloaded:
        st.caption(f"ğŸ“ pdfs/ ã‹ã‚‰ {len(preloaded)} ä»¶ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿")

    st.divider()
    st.header("ğŸ” é§…åãƒ»ã‚¨ãƒªã‚¢æ¤œç´¢")
    keyword = st.text_input(
        "é§…åãƒ»å¸‚åŒºç”ºæ‘",
        placeholder="ä¾‹ï¼šçŸ¢å‘ã€æ¨ªæµœã€æ–°å®¿ã€å·å´å¸‚å¹¸åŒº",
        help="é§…åã‚’å…¥åŠ›ã™ã‚‹ã¨å‘¨è¾ºã‚¨ãƒªã‚¢ã®åº—èˆ—ã‚’åŠå¾„æŒ‡å®šã§çµã‚Šè¾¼ã‚ã¾ã™"
    )
    radius_km = st.slider("æ¤œç´¢åŠå¾„ (km)", 1, 30, 10)

# â”€â”€ PDFè§£æ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class _FileProxy:
    def __init__(self, p):
        self.name = p.name
        self._data = p.read_bytes()
        self._pos = 0
    def read(self, n=-1):
        d = self._data[self._pos:]; self._pos = len(self._data); return d
    def seek(self, p): self._pos = p

sources = list(uploaded or []) + [_FileProxy(p) for p in preloaded]

if not sources:
    st.info("ğŸ‘† ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
    st.stop()

all_stores = []
for src in sources:
    try:
        all_stores.extend(extract_stores_from_pdf(src, source_type="upload"))
    except Exception as e:
        st.error(f"âŒ {src.name}: {e}")

if not all_stores:
    st.error("åº—èˆ—æƒ…å ±ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
    st.stop()

# â”€â”€ éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all_prefs = sorted(set(s.get("pref", "") for s in all_stores if s.get("pref")))
with st.sidebar:
    selected_prefs = st.multiselect("éƒ½é“åºœçœŒã§çµã‚Šè¾¼ã¿", all_prefs, default=all_prefs)

# â”€â”€ é§…åâ†’åº§æ¨™â†’å‘¨è¾ºã‚¨ãƒªã‚¢çµã‚Šè¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
kw = keyword.strip()
station_coord = None
nearby_areas = []
search_mode = "keyword"  # "station" or "keyword"

if kw:
    coord = get_station_coord(kw)
    if coord:
        station_coord = coord
        nearby_areas = get_nearby_areas(coord[0], coord[1], radius_km)
        search_mode = "station"

# â”€â”€ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
filtered = [s for s in all_stores if s.get("pref") in selected_prefs]

if kw:
    if search_mode == "station" and nearby_areas:
        # é§…ãƒ¢ãƒ¼ãƒ‰ï¼šå‘¨è¾ºã‚¨ãƒªã‚¢ã®ä½æ‰€ã‚’æŒã¤åº—èˆ—
        filtered = [
            s for s in filtered
            if any(area in s.get("address", "") for area in nearby_areas)
        ]
    else:
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ¢ãƒ¼ãƒ‰ï¼šä½æ‰€ãƒ»åº—èˆ—åã®éƒ¨åˆ†ä¸€è‡´
        filtered = [
            s for s in filtered
            if kw in s.get("address", "") or kw in s.get("name", "")
               or kw.replace("é§…","") in s.get("address", "")
        ]

# â”€â”€ ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if kw and search_mode == "station":
    st.markdown(
        f"ğŸ“ **{kw}** å‘¨è¾º **{radius_km}km** ä»¥å†…ã®ã‚¨ãƒªã‚¢: "
        f"`{'` `'.join(nearby_areas[:6])}{'` ãªã©' if len(nearby_areas)>6 else '`'}"
    )
    st.markdown(f"å…¨ **{len(all_stores)}** ä»¶ä¸­ **{len(filtered)}** ä»¶ã‚’è¡¨ç¤º")
elif kw:
    st.markdown(f"å…¨ **{len(all_stores)}** ä»¶ä¸­ **{len(filtered)}** ä»¶ï¼ˆã€Œ{kw}ã€ã§çµã‚Šè¾¼ã¿ï¼‰")
else:
    st.markdown(f"å…¨ **{len(all_stores)}** ä»¶ã‚’è¡¨ç¤º")

# â”€â”€ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if filtered and kw:
    col1, col2 = st.columns(2)
    with col1:
        # Googleãƒãƒƒãƒ—ã§é§…å‘¨è¾ºã‚’é–‹ã
        gmap_q = urllib.parse.quote(kw)
        st.link_button(
            f"ğŸ—ºï¸ ã€Œ{kw}ã€å‘¨è¾ºã‚’Googleãƒãƒƒãƒ—ã§é–‹ã",
            f"https://www.google.com/maps/search/{gmap_q}",
            use_container_width=True,
        )
    with col2:
        df_dl = pd.DataFrame([{
            "åº—èˆ—å": s["name"], "ä½æ‰€": s["address"], "é›»è©±": s.get("tel",""),
            "GoogleMap": "https://www.google.com/maps/search/?api=1&query="
                         + urllib.parse.quote(s["address"])
        } for s in filtered])
        st.download_button(
            "â¬‡ï¸ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogleãƒã‚¤ãƒãƒƒãƒ—ç”¨ï¼‰",
            df_dl.to_csv(index=False).encode("utf-8-sig"),
            file_name=f"å„ªå¾…_{kw or 'å…¨ä»¶'}.csv", mime="text/csv",
            use_container_width=True,
        )

if not filtered:
    if kw and search_mode == "station":
        st.warning(f"ã€Œ{kw}ã€å‘¨è¾º {radius_km}km ä»¥å†…ã«åº—èˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚åŠå¾„ã‚’åºƒã’ã‚‹ã‹ã€å¸‚åŒºç”ºæ‘åã§ç›´æ¥æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
    elif kw:
        st.warning(f"ã€Œ{kw}ã€ã«ä¸€è‡´ã™ã‚‹åº—èˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\nğŸ’¡ **ãƒ’ãƒ³ãƒˆ**: çŸ¢å‘é§…ã®ã‚ˆã†ãªé§…åã¯ã€ŒçŸ¢å‘ã€ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆé§…ãƒ‡ãƒ¼ã‚¿ã«ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆã€åŠå¾„æ¤œç´¢ãŒä½¿ãˆã¾ã™ï¼‰")
    else:
        st.info("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

st.divider()

# â”€â”€ åº—èˆ—ãƒªã‚¹ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pref_order = {p: i for i, p in enumerate(all_prefs)}
filtered_sorted = sorted(
    filtered,
    key=lambda s: (pref_order.get(s.get("pref",""), 999), s.get("address",""))
)

cur_pref = None
for s in filtered_sorted:
    pref = s.get("pref", "")
    if pref != cur_pref:
        cur_pref = pref
        st.subheader(f"ğŸ“ {pref}")

    addr = s.get("address", "")
    gmap_url = "https://www.google.com/maps/search/?api=1&query=" + urllib.parse.quote(addr)

    # ã©ã®ã‚¨ãƒªã‚¢ã«ãƒãƒƒãƒã—ãŸã‹è¡¨ç¤º
    matched_area = next((a for a in nearby_areas if a in addr), "") if nearby_areas else ""

    c1, c2 = st.columns([6, 1])
    with c1:
        area_hint = f'<div class="area-hint">ğŸ“Œ {matched_area}</div>' if matched_area else ""
        st.markdown(
            f'<div class="store-card">'
            f'<div class="store-name">{s.get("name","")}</div>'
            f'<div class="store-addr">ğŸ“® {addr}</div>'
            f'<div class="store-tel">ğŸ“ {s.get("tel","")}</div>'
            f'{area_hint}'
            f'</div>',
            unsafe_allow_html=True,
        )
    with c2:
        st.link_button("ğŸ—ºï¸ åœ°å›³", gmap_url, use_container_width=True)
